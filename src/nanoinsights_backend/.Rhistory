if (length(filt_genes) > 0) {
log_elements_string <- paste(filt_genes, collapse = ",")
write_log(sprintf("In total %d/%d genes did not pass the lowly expressed gene filtering step", length(filt_genes), nrow(rawCounts)), level = "INFO")
write_log("The following genes were filtered out (filter_lowlyExpr_genes):", level = "INFO", details = log_elements_string)
write(filt_genes, file = paste(results, "/filter_lowlyExpr_genes.tsv", sep = ""), append = FALSE, sep = ",")
} else {
write_log("No genes were filtered out (filter_lowlyExpr_genes)", level = "INFO")
}
}, error = function(e) {
write_log("Error filtering lowly expressed genes", level = "ERROR", details = e$message)
})
rm(keep, edgeR_table2, nofilt_genes)
}
## 2. Filtering out genes based on Negative Control genes
if (opt$filter_genes_on_negCtrl) {
write_log("Filtering out genes based on Negative Controls", level = "INFO")
tryCatch({
orig_matrix <- raw_expression
rownames(orig_matrix) <- orig_matrix$Gene
orig_matrix$Gene <- NULL
meanNC <- apply(orig_matrix[orig_matrix$Class == "Negative", 2:ncol(orig_matrix)], 2, mean)
standardDev <- apply(orig_matrix[orig_matrix$Class == "Negative", 2:ncol(orig_matrix)], 2, sd)
final_threshold <- meanNC + (2 * standardDev)
total_num <- nrow(orig_matrix[orig_matrix$Class == "Endogenous", ])
orig_matrix <- orig_matrix[orig_matrix$Class == "Endogenous", 2:ncol(orig_matrix)] - final_threshold[col(orig_matrix[2:ncol(orig_matrix)])]
has.neg <- apply(orig_matrix, 1, function(row) sum(row <= 0) > ceiling((ncol(orig_matrix) * 85) / 100))
has.neg <- names(which(has.neg))
if (length(has.neg) > 0) {
log_elements_string <- paste(has.neg, collapse = ",")
write_log(sprintf("In total %d/%d genes did not pass the NC filtering step", length(has.neg), total_num), level = "INFO")
write_log("The following genes were filtered out (filter_genes_on_negCtrl):", level = "INFO", details = log_elements_string)
write(has.neg, file = paste(results, "/filter_genes_on_negCtrl.tsv", sep = ""), append = FALSE, sep = ",")
} else {
write_log("No genes were filtered out (filter_genes_on_negCtrl)", level = "INFO")
}
filt_genes <- unique(c(filt_genes, has.neg))
}, error = function(e) {
write_log("Error filtering genes based on Negative Controls", level = "ERROR", details = e$message)
})
rm(orig_matrix, meanNC, standardDev, final_threshold, has.neg)
}
## 3. Remove samples based on Negative Controls
if (opt$filter_samples_on_negCtrl) {
write_log("Removing samples based on Negative Controls", level = "INFO")
tryCatch({
orig_matrix <- raw_expression
rownames(orig_matrix) <- orig_matrix$Gene
orig_matrix$Gene <- NULL
orig_matrix <- orig_matrix[!(orig_matrix$Class == "Endogenous" & rownames(orig_matrix) %in% filt_genes), ]
meanNC <- apply(orig_matrix[orig_matrix$Class == "Negative", 2:ncol(orig_matrix)], 2, mean)
standardDev <- apply(orig_matrix[orig_matrix$Class == "Negative", 2:ncol(orig_matrix)], 2, sd)
final_threshold <- meanNC + (2 * standardDev)
total_num <- ncol(orig_matrix) - 1
orig_matrix <- orig_matrix[orig_matrix$Class == "Endogenous", 2:ncol(orig_matrix)] - final_threshold[col(orig_matrix[2:ncol(orig_matrix)])]
removed_samples <- apply(orig_matrix, 2, function(col) sum(col < 1) > ceiling((nrow(orig_matrix) * 85) / 100))
removed_samples <- names(which(removed_samples))
raw_expression <- raw_expression[, !(colnames(raw_expression) %in% removed_samples)]
clinical_orig <- clinical_info
clinical_info <- clinical_info[!(rownames(clinical_info) %in% removed_samples), ]
pData <- pData[!(pData$BCAC_ID %in% removed_samples), ]
library_size <- library_size[!(rownames(library_size) %in% removed_samples), ]
filt_samples <- unique(c(filt_samples, removed_samples))
if (length(removed_samples) > 0) {
log_elements_string <- paste(removed_samples, collapse = ",")
write_log(sprintf("In total %d/%d samples did not pass the NC filtering step", length(removed_samples), total_num), level = "INFO")
write_log("The following samples were filtered out (filter_samples_on_negCtrl):", level = "INFO", details = log_elements_string)
write(removed_samples, file = paste(results, "/filter_samples_on_negCtrl.tsv", sep = ""), append = FALSE, sep = ",")
} else {
write_log("No samples were filtered out (filter_samples_on_negCtrl)", level = "INFO")
}
}, error = function(e) {
write_log("Error removing samples based on Negative Controls", level = "ERROR", details = e$message)
})
rm(orig_matrix, meanNC, standardDev, final_threshold, removed_samples)
}
## 4. Remove outlier samples
if (opt$remove_outlier_samples) {
write_log("Removing outlier samples based on IQR", level = "INFO")
tryCatch({
raw_expression <- raw_expression[, !(colnames(raw_expression) %in% potential_outliers)]
clinical_info <- clinical_info[!(rownames(clinical_info) %in% potential_outliers), ]
pData <- pData[!(pData$BCAC_ID %in% potential_outliers), ]
library_size <- library_size[!(rownames(library_size) %in% potential_outliers), ]
filt_samples <- unique(c(filt_samples, potential_outliers))
}, error = function(e) {
write_log("Error removing outlier samples", level = "ERROR", details = e$message)
})
}
##### Applying Gene-Based Filtering #####
write_log("Applying gene-based filters if opted", level = "INFO")
tryCatch({
# Removing filtered genes and samples
raw <- raw[!(raw$Name %in% filt_genes), ]
write_log("Removed filtered genes from the raw dataframe", level = "INFO")
raw_expression <- raw_expression[!(raw_expression$Gene %in% filt_genes), ]
write_log("Excluded filtered genes from the raw_expression dataframe", level = "INFO")
rawCounts.filt <- data.frame(edgeR_table$counts)
rawCounts.filt <- rawCounts.filt[!(rownames(rawCounts.filt) %in% filt_genes), !(colnames(rawCounts.filt) %in% filt_samples)]
write_log("Excluded filtered genes and samples from the rawCounts.filt dataframe", level = "INFO")
}, error = function(e) {
write_log("Error during gene-based filtering", level = "ERROR", details = e$message)
})
# Clean up
rm(edgeR_table, rawCounts, filt_samples, filt_genes)
##### Reordering All Filtered Dataframes #####
write_log("Reordering all filtered dataframes", level = "INFO")
tryCatch({
clinical_info <- clinical_info[order(clinical_info$Condition), ]
write_log("Reordered clinical_info by the Condition column", level = "INFO")
pData <- pData[match(row.names(clinical_info), pData$BCAC_ID), ]
write_log("Reordered pData based on clinical_info", level = "INFO")
raw_expression <- raw_expression[, match(c("Gene", "Class", row.names(clinical_info)), colnames(raw_expression))]
write_log("Reordered raw_expression based on clinical_info", level = "INFO")
rawCounts.filt <- rawCounts.filt[, match(row.names(clinical_info), colnames(rawCounts.filt))]
write_log("Reordered rawCounts.filt based on clinical_info", level = "INFO")
}, error = function(e) {
write_log("Error during reordering of filtered dataframes", level = "ERROR", details = e$message)
})
# Clean up
rm(initialqc, exploratory_analysis, iqr_analysis, pData)
# Perform post-filtering exploratory analysis if any filtering options are enabled
if (opt$filter_lowlyExpr_genes || opt$filter_genes_on_negCtrl || opt$filter_samples_on_negCtrl || opt$remove_outlier_samples) {
write_log("Starting post-filtering exploratory analysis", level = "INFO")
# Call the post-filtering exploratory analysis function
postfilt_expl_analysis()
}
dds <- DESeqDataSetFromMatrix(countData = rawCounts.filt, colData = clinical_info, design = ~ Condition)
write_log("Converting DDS to rlog", level = "INFO")
suppressMessages(suppressWarnings(rld <- rlog(dds, blind = TRUE, fitType = "local")))
rld_assay <- assay(rld)  # Cache for reuse
write_log("Calculating PCA and saving it in data_pca", level = "INFO")
data_pca <- plotPCA(rld, intgroup = "Condition", returnData = TRUE)
percentVar <- round(100 * attr(data_pca, "percentVar"))
write_log("Merging data_pca with library_size", level = "INFO")
library_data <- library_size[, c("CartridgeID", "Endogenous", "Total", "Date")]
data_pca <- merge(data_pca, library_data, by.x = 0, by.y = 0)
row.names(data_pca) <- data_pca$Row.names
data_pca$Row.names <- NULL
data_pca <- data_pca[match(row.names(clinical_info), row.names(data_pca)), ]
group_df <- data.frame(row.names = row.names(data_pca),
Condition = data_pca$Condition,
Cartridge = data_pca$CartridgeID)
unique_runs <- as.vector(unique(clinical_info$CartridgeID))
# Create batch list for color mapping
batch_list <- setNames(paletteColors[1:length(unique_runs)], unique_runs)
group_df_colors <- list("Condition" = setNames(c(colors[1], colors[2]), unique(data_pca$Condition)),
"Cartridge" = batch_list)
# Generating Spearman correlation matrix
write_log("Calculating Spearman correlation matrix", level = "INFO")
spearman_correlation <- cor(assay(rld), method = "spearman")
grid.grabExpr({
pheatmap(spearman_correlation,
main = "Sample correlation heatmap on filtered data\n(based on Spearman correlation)",
fontsize = 8,
border_color = NA,
angle_col = 90,
treeheight_row = 0,
annotation_col = group_df,
annotation_colors = group_df_colors,
color = colorRampPalette(brewer.pal(n = 7, name = "YlGnBu"))(100))}))
grid.grabExpr({
pheatmap(spearman_correlation,
main = "Sample correlation heatmap on filtered data\n(based on Spearman correlation)",
fontsize = 8,
border_color = NA,
angle_col = 90,
treeheight_row = 0,
annotation_col = group_df,
annotation_colors = group_df_colors,
color = colorRampPalette(brewer.pal(n = 7, name = "YlGnBu"))(100))})
# Convert group_df_colors to a format usable by heatmaply
col_side_colors <- data.frame(
Condition = group_df_colors$Condition[as.character(group_df$Condition)],
Cartridge = group_df_colors$Cartridge[as.character(group_df$Cartridge)],
row.names = row.names(group_df)
)
# Add hover information to column annotations
col_side_hover <- list(
Condition = paste0("Sample: ", group_df$Sample,
"<br>Condition: ", group_df$Condition),
Cartridge = paste0("Sample: ", group_df$Sample,
"<br>CartridgeID: ", group_df$Cartridge)
)
heatmaply_cor(spearman_correlation,
file = paste0(html_results, "/sample.correlation.filtered.html"),
limits = NULL,
colors = colorRampPalette(brewer.pal(n = 7, name = "YlGnBu"))(100),
main = "Sample correlation (Spearman) heatmap on filtered data",
key.title = NULL,
hide_colorbar = FALSE,
col_side_colors = col_side_colors,
col_side_colors = col_side_colors,  # Apply colors
col_side_hover = col_side_hover,   # Add hover information
column_text_angle = 90,
dendrogram = "column",
fontsize_col = 7,
# fontsize_row = 7,
showticklabels = c(FALSE, TRUE))
heatmaply_cor(spearman_correlation,
file = paste0(html_results, "/sample.correlation.filtered.html"),
limits = NULL,
colors = colorRampPalette(brewer.pal(n = 7, name = "YlGnBu"))(100),
main = "Sample correlation (Spearman) heatmap on filtered data",
key.title = NULL,
hide_colorbar = FALSE,
col_side_colors = col_side_colors,
col_side_hover = col_side_hover,   # Add hover information
column_text_angle = 90,
dendrogram = "column",
fontsize_col = 7,
# fontsize_row = 7,
showticklabels = c(FALSE, TRUE))
heatmaply_cor(spearman_correlation,
file = paste0(html_results, "/sample.correlation.filtered.html"),
limits = NULL,
colors = colorRampPalette(brewer.pal(n = 7, name = "YlGnBu"))(100),
main = "Sample correlation (Spearman) heatmap on filtered data",
key.title = NULL,
hide_colorbar = FALSE,
col_side_colors = col_side_colors,
col_side_hover = col_side_hover,   # Add hover information
column_text_angle = 90,
dendrogram = "column",
fontsize_col = 7,
# fontsize_row = 7,
showticklabels = c(TRUE, FALSE))
View(group_df)
group_df$Cartridge
# Convert group_df_colors to a format usable by heatmaply
col_side_colors <- data.frame(
Condition = group_df_colors$Condition[as.character(group_df$Condition)],
Cartridge = group_df_colors$Cartridge[as.character(group_df$Cartridge)],
row.names = row.names(group_df)
)
View(col_side_colors)
# Add hover information to column annotations
col_side_hover <- list(
Condition = paste0("Sample: ", row.names(group_df),
"<br>Condition: ", group_df$Condition),
Cartridge = paste0("Sample: ", row.names(group_df),
"<br>CartridgeID: ", group_df$Cartridge)
)
View(col_side_hover)
heatmaply_cor(spearman_correlation,
file = paste0(html_results, "/sample.correlation.filtered.html"),
limits = NULL,
colors = colorRampPalette(brewer.pal(n = 7, name = "YlGnBu"))(100),
main = "Sample correlation (Spearman) heatmap on filtered data",
key.title = NULL,
hide_colorbar = FALSE,
col_side_colors = col_side_colors,
col_side_hover = col_side_hover,   # Add hover information
column_text_angle = 90,
dendrogram = "column",
fontsize_col = 7,
# fontsize_row = 7,
showticklabels = c(TRUE, FALSE))
?heatmaply_cor
?heatmaply_cor
View(spearman_correlation)
install.packages(pheatmap)
install.packages("pheatmap")
suppressPackageStartupMessages(
suppressMessages(suppressWarnings({
library("reticulate")
library("optparse")
library("ggplot2")
library("plotly")
library("reshape2")
library("tidyverse")
library("RColorBrewer")
library("NanoStringClustR")
library("NanoTube")
library("RUVSeq")
library("ctrlGene")
library("htmltools")
library("formattable")
library("DT")
library("ggrepel")
library("bslib")
set.seed(42)
})))
# Function to create directories
create_directory <- function(path, description) {
tryCatch({
dir.create(path, showWarnings = FALSE, recursive = TRUE)
write_log(paste("Successfully created", description, "at:", path), level = "INFO")
}, error = function(e) {
write_log(paste("Failed to create", description, ":", e$message), level = "ERROR")
})
}
# Enhanced Function to Read and Check Data with Specific File Extension Logic and NA Column Check
read_and_check <- function(file_path, var_name, description) {
tryCatch({
# Determine delimiter based on file extension
delimiter <- if (grepl("\\.(txt|csv)$", file_path, ignore.case = TRUE)) {
","
} else if (grepl("\\.tsv$", file_path, ignore.case = TRUE)) {
"\t"
} else {
stop("Unsupported file format. Supported formats are .txt, .csv, and .tsv.")
}
# Read the file
data <- read.table(file_path, sep = delimiter, header = TRUE, check.names = FALSE)
# Check for columns entirely filled with NA
na_columns <- which(colSums(is.na(data)) == nrow(data))
if (length(na_columns) > 4) {
stop(paste("The data contains", length(na_columns), "columns entirely filled with NA values. Please check the file:", file_path))
}
# Log success
write_log(paste("Successfully imported", description, "from:", file_path), level = "INFO")
return(data)
}, error = function(e) {
# Log and re-raise error
write_log(paste("Error importing", description, "from:", file_path, "-", e$message), level = "ERROR")
})
}
######### TO DELETE
raw_data <- "/Users/stavris/Desktop/NanoInsights_Uploads/I7UH1YP2BL1LAD/test_set"
clinical_data <- "/Users/stavris/Desktop/NanoInsights_Uploads/I7UH1YP2BL1LAD/test_set/clinical_data.csv"
log_file <- "/Users/stavris/Desktop/NanoInsights_Uploads/I7UH1YP2BL1LAD/I7UH1YP2BL1LAD_log.json"
groups_capital <- c(str_to_title("negative"), str_to_title("positive"))
opt <- data.frame(1,6)
opt$currdir <- "~/Desktop/Projects/nStringAnalysis/nanoinsights/src/nanoinsights_backend"
opt$training_mat <- "/Users/stavris/Desktop/NanoInsights_Uploads/I7UH1YP2BL1LAD/output_results/trainingset_normalisation/quantile-normalised.matrix.ml.tsv"
opt$refgenes <- "hkNpos"
opt$minref <- 5
opt$k_factor <- 1
opt$upper_limit <- 2.25
bdlimits <- c(0.1, opt$upper_limit)
results <- file.path(dirname(raw_data), "output_results", "testset_normalisation")
html_results <- file.path(dirname(raw_data), "html_results", "testset_normalisation")
######### TO DELETE
# Import all necessary for the analysis functions
source(file.path(opt$currdir, "helper_functions.R"))
# Initialize Logging
write_log("### INITIALISING TEST SET ANALYSIS (R) ###", level = "INFO")
# Create Directories
create_directory(results, "results directory")
create_directory(html_results, "HTML results directory")
### Import Data
write_log("### IMPORTING NECESSARY DATA ###", level = "INFO")
pData <- read_and_check(file.path(raw_data, "pData.tsv"), "pData", "metadata (pData)")
raw <- read_and_check(file.path(raw_data, "raw.tsv"), "raw", "raw data")
raw_expression <- read_and_check(file.path(raw_data, "raw_expression.tsv"), "raw_expression", "raw expression data")
clinical_info <- read_and_check(clinical_data, "clinical_info", "clinical sample sheet")
# Process Clinical Data
write_log("### PROCESSING CLINICAL DATA ###", level = "INFO")
tryCatch({
# Remove file extensions from filenames
clinical_info$Filename <- gsub(".{4}$", "", clinical_info$Filename)
# Merge clinical_info with pData
clinical_info <- merge(clinical_info, pData[, c("BCAC_ID", "CartridgeID")], by.x = "Filename", by.y = "BCAC_ID")
clinical_info <- clinical_info %>% select(Sample = Filename, Condition, CartridgeID)
row.names(clinical_info)  <- clinical_info$Sample
# Convert Condition to title case
clinical_info$Condition <- str_to_title(clinical_info$Condition)
# Set Condition as a factor with levels from groups_capital
clinical_info$Condition <- factor(clinical_info$Condition, levels = groups_capital)
clinical_info$CartridgeID <- factor(clinical_info$CartridgeID, levels = unique(clinical_info$CartridgeID))
write_log("Successfully processed clinical data.", level = "INFO")
}, error = function(e) {
write_log(paste("Error processing clinical data:", e$message), level = "ERROR")
})
### Generate Initial QC Report
write_log("### GENERATING INITIAL QC REPORT ###", level = "INFO")
tryCatch({
# Define selected columns for QC stats
selected_columns <- c("BCAC_ID", "Date", "CartridgeID", "imagingQC", "bindingDensityQC", "positiveLinearityQC", "limitOfDetectionQC")
# Calculate library size metrics
library_size <- tryCatch({
data.frame(
Endogenous = colSums(raw_expression[raw_expression$Class == "Endogenous", 3:ncol(raw_expression)]),
Housekeepings = colSums(raw_expression[raw_expression$Class == "Housekeeping", 3:ncol(raw_expression)]),
Positives = colSums(raw_expression[raw_expression$Class == "Positive", 3:ncol(raw_expression)]),
Negatives = colSums(raw_expression[raw_expression$Class == "Negative", 3:ncol(raw_expression)]),
Total = colSums(raw_expression[, 3:ncol(raw_expression)])
)
}, error = function(e) {
write_log("Error calculating library size metrics", level = "ERROR", details = e$message)
})
write_log("Library size metrics calculated successfully.", level = "INFO")
# Merge with metadata and clinical info
library_size <- merge(library_size, pData[, selected_columns], by.x = 0, by.y = "BCAC_ID")
library_size <- merge(library_size, clinical_info[, c("Sample", "Condition")], by.x = "Row.names", by.y = "Sample")
row.names(library_size) <- library_size$Row.names
library_size$Row.names <- NULL
write_log("Library size merged with metadata and clinical info.", level = "INFO")
# Reorder data based on clinical info
clinical_info <- clinical_info[order(clinical_info$Condition), ]
library_size <- library_size[match(row.names(clinical_info), row.names(library_size)), ]
pData <- pData[match(row.names(clinical_info), pData$BCAC_ID), ]
raw_expression <- raw_expression[, match(c("Gene", "Class", row.names(clinical_info)), colnames(raw_expression))]
write_log("Data reordered based on clinical info.", level = "INFO")
# Prepare interactive stats table for primary QC
output_stats <- pData[, c("BCAC_ID", "Date", "CartridgeID", "imaging", "bindingDensity", "positiveLinearity", "limitOfDetectionQC")]
visual_color <- function(value, threshold) {
ifelse(value < threshold, scales::col_numeric(c("#a4161a", "#e5383b", "#ff758f"), domain = c(0, threshold))(value), "white")
}
custom_css <- "table.dataTable {font-family: 'Helvetica', sans-serif; font-size: 14px;}
p, ul {font-family: 'Helvetica', sans-serif; font-size: 12px; margin-top: 10px;}
ul {padding-left: 40px;}
li {font-size: 12px; line-height: 1.5;}"
# Apply the visual colour formatting to a DT table
datatable_with_colors <- datatable(output_stats, options = list(
pageLength = 10,  # Number of samples to be shown
autoWidth = TRUE,  # Automatically adjust column widths
ordering = TRUE),
rownames = FALSE) %>% formatStyle("imaging",
backgroundColor = styleInterval(c(0.75), c("#ff758f", "white"))) %>%
formatStyle("bindingDensity",
color = styleInterval(bdlimits, c("#e5383b", "black", "#e5383b"))) %>%
formatStyle("positiveLinearity",
backgroundColor = styleInterval(c(0.95), c("#ff758f", "white"))) %>%
formatStyle("limitOfDetectionQC",
color = styleEqual(c("True", "False"), c("black", "#e5383b")))
# Add explanatory text
explanatory_text <- HTML(sprintf(
"<p style='font-family: Helvetica, sans-serif; font-size: 12px; margin-top: 20px;'>
This table provides the initial quality control (QC) metrics for the input dataset.
Samples highlighted in red indicate values requiring attention, but note that some highlighted values might be close to the thresholds and therefore acceptable.
The thresholds used for each metric are as follows:
<ul>
<li><strong>Imaging:</strong> Values must be higher than 0.75.</li>
<li><strong>Binding Density:</strong> Values must be between 0.1 and %s.</li>
<li><strong>Positive Linearity:</strong> Values must be higher than 0.95.</li>
<li><strong>Limit of Detection QC:</strong> TRUE/FALSE (indicating pass/fail).</li>
</ul>
</p>",
opt$upper_limit
))
# Combine CSS, datatable, and explanatory text into a single HTML layout
html_output <- tagList(tags$style(HTML(custom_css)), datatable_with_colors, explanatory_text)
# Save the combined HTML content using htmltools::save_html
save_html(html_output, file = file.path(html_results, "initial_stats.html"))
write_log("Interactive QC report generated and saved as HTML.", level = "INFO")
# Save initial stats as TSV
write.table(pData, file = file.path(results, "initial_stats.tsv"), sep = "\t", row.names = FALSE, quote = FALSE)
write_log("Initial stats saved to TSV.", level = "INFO")
# Update QC flags
selected_columns <- c('imagingQC', 'bindingDensityQC', 'positiveLinearityQC', 'limitOfDetectionQC')
library_size[selected_columns] <- lapply(library_size[selected_columns], function(x) ifelse(x == "True", "No flag", ifelse(x == "False", "Potential outlier sample", x)))
# Save library size with updated QC flags
write.table(data.frame("SampleNames" = rownames(library_size), library_size), file = file.path(results, "library_size.tsv"), sep = "\t", row.names = FALSE, quote = FALSE)
write_log("Library size with QC flags saved to TSV.", level = "INFO")
rm(datatable_with_colors, html_output, output_stats, visual_color, explanatory_text, custom_css)
}, error = function(e) {
write_log("Error generating initial QC report", level = "ERROR", details = e$message)
})
######################### INITIAL NANOSTRING QC
write_log("### GENERATING NANOSTRING STANDARD QC METRICS PLOTS ###", level = "INFO")
tryCatch({
# Attempt to run the initial QC process
initialqc()
# Log a success message upon completion
write_log("Successfully completed NanoString QC metrics generation.", level = "INFO")
}, error = function(e) {
# Log a detailed error message with the error message from the exception
write_log("Error during NanoString QC metrics generation", level = "ERROR", details = e$message)
})
######################### NORMALISATION
write_log("### DATA NORMALISATION ###", level = "INFO")
# Log the start of data filtering and preparation
write_log("Starting data filtering and preparation", level = "INFO")
training_genes <- read.table(opt$training_mat, header = TRUE, sep = "\t")[, 1]
View(raw)
raw_expression.filt <- raw_expression %>%
filter(Class %in% c("Housekeeping", "Negative", "Positive") |
(Class == "Endogenous" & Gene %in% training_genes))
View(raw_expression.filt)
rawCounts <- raw_expression %>%
filter(Class == "Endogenous") %>%
select(-Class)  # Remove 'Class' column to keep gene counts only
row.names(rawCounts) <- rawCounts$Gene  # Set 'Gene' as row names
rawCounts$Gene <- NULL  # Remove the 'Gene' column
View(rawCounts)
hk_genes <- raw[raw$CodeClass == "Housekeeping", 2]
View(rawCounts)
# Filter rows in rawCounts based on row names matching training_genes
rawCounts.filt <- rawCounts[rownames(rawCounts) %in% training_genes, ]
library(gProfiler)
install.packages("gprofiler2")
library(gprofiler2)
library("gprofiler2")
?gost
library("tools")
library("stringr")
setwd("/Users/stavris/Desktop/Projects/nStringAnalysis/nanoinsights/src/nanoinsights_backend")
library("tools")
library("stringr")
# List of script files
script_files <- c("trainingset_normalisation.R", "testset_normalisation.R", "helper_functions.R")
# Function to extract required libraries from a script
extract_packages <- function(script) {
lines <- readLines(script)
# Look for library(), require(), and package::function calls
packages <- unique(c(
str_match(lines, "library\\(([^)]+)\\)")[,2],
str_match(lines, "require\\(([^)]+)\\)")[,2],
str_match(lines, "([a-zA-Z0-9._]+)::")[,2]
))
packages <- na.omit(packages)
return(packages)
}
# Loop through each script and collect packages
all_packages <- unlist(lapply(script_files, extract_packages))
# Remove duplicates
unique_packages <- unique(all_packages)
# Print the packages
print(unique_packages)
# Write packages to a file
writeLines(unique_packages, "required_R_packages.txt")
